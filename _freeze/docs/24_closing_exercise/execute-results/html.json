{
  "hash": "7acf114444c1e39139633c5916da2d82",
  "result": {
    "markdown": "# Closing exercise\n\nBelow are some important, and hopefully useful, practical things to keep in mind.\n\n## Difference between regression and correlation\n\nCorrelation: tells us about the relationship between two variables. It doesn't tell us, however, **how** those variables are related. That is what regression does for us. Regression not only tells us whether two variables are related, but they allow us to examine how one variable might **cause** the other.\n\nOne example of calculating a correlation is through a t-test or a difference of means test.\n\n## Difference of means test (t-test)\n\nTo perform a difference of means test, also called a t-test, in R is quite straight forward. You can just use the `t.test()` function to do this. Then you'd want to interpret the t-value calculated by it, which is just the difference in the means between the two variables and then the p-value to determine whether that difference in the means is statistically significant or not.\n\n```{.r}\nt.test(MYDATASET$Y ~ MYDATASET$X)\n```\n\n## When asked to report regression results, put it in a table\n\nFor many beginners, they often will either forget reporting the results of a regression altogether or just using the `summary()` function and pasting the output into the documents.\n\nBoth of these provide incomplete information that will make it harder for you to interpret the results of your regression and it will also give the reader insufficient amount of information to see the results of your analyses.\n\nSo, be sure that you use either the `stargazer()` function from the `stargazer` package [@stargazer] or the `modelsummary()` function from the `modelsummary` package. These are relatively easy to use. Here is an example below.\n\n```{.r}\n\n# Run my regression\nregression <- lm( # store the result in an object called regression\n    formula = Y ~ X + Z # Fit this regression where Y is the dependent variable and X and Z are the independent variables\n    , data = MYDATASET # These variables can be found in this dataset called MYDATASET\n)\n\n# Put the regression results in a table\n    #* With the stargazer package\nstargazer( # make a table of regression outputs\n    regression # here is the stored result from my regression above\n    , type = \"text\" # make it a table that I can copy and paste into a word document\n)\n    #* With the modelsummary package\nmodelsummary( # make a table of regression outputs\n    regression # here is the stored result from my regression above\n    , stars = TRUE # include stars based on p-values\n    , output = \"myRegressionTable.docx\" # store the table in a word document called myRegressionTable\n)\n```\n\n## Be careful about how to interpret your regression results!\n\nFolks often make the mistake of either only interpreting the $\\beta$ coefficient or, more commonly, only interpreting the statistical significance of the effect. Remember that we need to discuss both! The $\\beta$ coefficient tells us the size of the relationship between the two variables and the p-value tells us whether or not we believe that it is likely this relationship exists outside of our sample -- for our population.\n\nAnother problem that I see happens here is that people will only interpret the results for *some* of the variables in the regression. You should make sure that you interpret *all* of the variables in your regression model.\n\n### General template for interpreting regression results\n\n>For every one unit increase in [my independent variable], I'd expect a [$\\beta$] unit [increase/decrease] in my [dependent variable] when I hold my other independent variables constant. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\\beta$ coefficient this large or larger if the true relationship between these two variables was zero.\n\n### Template for interpreting regression results for a dichotomous independent variable\n\n>The difference between [the baseline category/what it means when the variable is 0] and [the category when the variable is 1] is [$\\beta$] units [greater/smaller] when I hold my other independent variables constant. This difference [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\\beta$ coefficient this large or larger if the true relationship between these two variables was zero.\n\n### Template for interpreting regression results with an interaction term\n\nFor the continuous independent variable:\n\n>When [the other independent variable] equals 0, a one unit increase in [my continuous independent variable], I'd expect a [$\\beta$] unit [increase/decrease] in my [dependent variable]. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\\beta$ coefficient this large or larger if the true relationship between these two variables was zero. \n\nFor the dichotomous independent variable:\n\n>When [the other independent variable] equals 0, a one unit increase in [my continuous independent variable], I'd expect a [$\\beta$] unit [increase/decrease] in my [dependent variable]. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\\beta$ coefficient this large or larger if the true relationship between these two variables was zero. \n\nFor the interaction term:\n\n>When [one of your continuous independent variables] increase by one unit, the difference between [the baseline category for your dichotmous independent variable/what it means when the dichotomous variable is zero] [increases/decreases]. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\\beta$ coefficient this large or larger if the true relationship was zero.\n\nYou can also interpret these results with a plot with the `visreg` package as well instead of a table. This can sometimes be easier for newer folks. You will still want to interpret the same components as you do above with a table, but you can do it with a table. You can use this code to make that plot with `visreg`.\n\n```{.r}\n# Run my regression\nregression <- lm( # store the result in an object called regression\n    formula = Y ~ Continuous_Variable + Dichotomous_Variable + Continuous_Variable:Dichotomous_Variable\n    , data = MYDATASET # These variables can be found in this dataset called MYDATASET\n)\n\nvisreg( # make a plot to show the expected value with an interaction\n    regression, # use the results from my regression model made above\n    ,\"Continous_Variable\" \n    , by = \"Dichotomous_Variable\"\n    , band=FALSE\n    , overlay=TRUE\n)\n```\n\nYou have another option to make the same plot with the `modelsummary` package.\n\n```{.r}\n# Run my regression\nregression <- lm( # store the result in an object called regression\n    formula = Y ~ Continuous_Variable + Dichotomous_Variable + Continuous_Variable:Dichotomous_Variable\n    , data = MYDATASET # These variables can be found in this dataset called MYDATASET\n)\n\nplot_predictions( # plot predicted values from this\n    regression, # plot the interaction model\n    condition = c(\"Continuous_Variable\", \"Dichotomous_Variable\")\n) +\ntheme_minimal() +\nlabs(\n    y = \"Y\",\n    x = \"Continuous_Variable\",\n    caption = \"Data source: MYDATASET.\\n Effect of Continous_Variable on Y, conditional on Dichotomous_Variable.\"\n)\n```\n\n### Interpreting the regression with confidence intervals\n\nIf you are asked to interpret the statistical significance of a regression model by its confidence intervals rather than the p-value, you can often use what is called a coefficient plot to do so!\n\nThese coefficient plots are relatively easy to create. One option would be to do this with the `modelsummary` package:\n\n```{.r}\n\n# Run my regression\nregression <- lm( # store the result in an object called regression\n    formula = Y ~ X + Z # Fit this regression where Y is the dependent variable and X and Z are the independent variables\n    , data = MYDATASET # These variables can be found in this dataset called MYDATASET\n)\n\nmodelplot( # make a plot with the CI's\n    regression # with the bivariate regression\n    ,coef_omit=\"Intercept\" # do not include the intercept term\n) +\ngeom_vline(\n    aes(xintercept = 0),\n    linetype = 2\n)\n```\n\nOR with the `texreg` package:\n\n```{.r}\n# Run my regression\nregression <- lm( # store the result in an object called regression\n    formula = Y ~ X + Z # Fit this regression where Y is the dependent variable and X and Z are the independent variables\n    , data = MYDATASET # These variables can be found in this dataset called MYDATASET\n)\n\nplotreg( # make a plot with the CI's\n    bivariate # with the bivariate regression\n    ,omit.coef = \"(Intercept)\" # do not include the intercept term\n)\n```\n\n## Logistic regression\n\nIf we have a dichotomous dependent variable (a outcome variable that is measured with only two categories), then linear regression is often insufficient. There are two problems that come about when we preform a standard linear regression on a dichotomous dependent variable.\n\n1. The predicted values from the linear regression for the outcome are often non-sensical. With the linear regression, we can get values that theoretically range from $-\\infty$ to $\\infty$. When we have a dichotomous outome where it can only take the value of 0 or 1, this is suboptimal. \n2. Because of linear regression's inability to come up with predicted values that are either 0 or 1, the residuals will have an unequal variance.\n\nLogistic regression seeks to correct for these two issues. Using a link function, logistic regression \"bends\" the line so that we can only get predicted values of either 0 or 1. This also is good for the variance of our residuals! For more details on logisitic regression, see [the logistic regression exercise](23_logits.qmd).\n\nInterpreting logistic regressions is a bit trickier because of this link function. When we fit a logistic regression, the coefficients are on the scale of **logged-odds**. Because of this, we have to interpret a table of results from our logistic regression in terms of logged-odds. See a template below for example:\n\n>The logged-odds of [the outcome of my dependent variable when it equals 1] [increases/decreases] when [my independent variable] [increases/decreases] holding all of my other independent variables at their mean value. This effect [is/is not] statistically significant.\n\n- When $\\beta = 0$, the logged-odds of the outcome reflected by the value of 1 for my dependent variable remains the same.\n- When $\\beta > 0$, the logged-odds of the outcome reflected by the value of 1 for my dependent variable increase.\n- When $\\beta < 0$, the logged-odds of the outcome reflected by the value of 1 for my dependent variable decrease.\n\nWe can take the exponent of our coefficient ($exp(\\beta)$) to retrieve the odds-ratio of an event occurring. In such a situation, we would interpret the results the following way:\n\n>The odds of [the outcome of my dependent variable when it equals 1] [increases/decreases] when [my independent variable] [increases/decreases] holding all of my other independent variables at their mean value. This effect [is/is not] statistically significant.\n\n- When $\\beta = 1$, the odds of the outcome reflected by the value of 1 for my dependent variable remains the same.\n- When $\\beta > 1$, the odds of the outcome reflected by the value of 1 for my dependent variable increase.\n- When $\\beta < 1$, the odds of the outcome reflected by the value of 1 for my dependent variable decrease.\n\nLogged-odds and odds are often still a bit too complicated for most folks. We can preform more calculations to try to make it even more natural for folks. To do this, we can do some algebra to calculate the predicted probability of an outcome occurring. Thankfully we have R to do this for us. We can do this with the `visreg` package [@visreg]. It is important to keep in mind that we can only put one of our independent variables on our x-axis. So when we are interpreting such a plot, we need to keep in mind that the predicted probability either increases or decreases as the variable on the x-axis increases. BUT with all of the other independent variables, they are being held at their mean value. If we want the other independent variables to have their values change too, we can with a little bit more effort. See [the exercise on logistic regressions](24_logits.qmd) for examples of this.\n\n## Testing your knowledge\n\n\n::: {.cell}\n\n:::\n\n\n- Why might I want to take the log of a variable?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\nTo make it appear as though there is less skew in the data. To bring large values closer to smaller values. Makes it appear more like a normal distribution.\n\n:::\n\n- What does the central tendency of a univariate descriptive statistic refer to?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\nIt is *one* way of describing a value I might expect to get if I randomly grabbed an observation from my data.\n:::\n\n- What are two calculations I can make to describe the central tendency of a variable?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n- Mean\n- Median\n:::\n\n- What does the dispersion or the spread of a univariate descriptive statistic refer to?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\nIt goes beyond saying what the average value is for a variable in my data, but it tells me how spread out they are. I need to know more than what the median house price is; I may want to know whether all houses are around that median or if there are some *really* cheap houses and some *really* expensive houses.\n:::\n\n- What are the two calculations I can make to describe the spread or dispersion of a variable?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n- Variance ($\\sigma^2$)\n- Standard deviation ($\\sigma$)\n:::\n\n- When you are asked to describe a variable, what are the two things that you should include to describe it?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n- Central tendency\n- Spread/dispersion\n\nI need to do this because one of these things on their own is not sufficient for me to understand what the bulk of observations look like on that observation (central tendency -- mean or median) or I won't understand how spread out observations are from that central tendency (spread/dispersion -- variance or standard deviation).\n:::\n\n- An independent variable refers to what?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nThe variable that we think *explains*, has an *effect upon* or *predicts* another variable.\n:::\n\n- A dependent variable refers to what?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nThe variable that we think is the *outcome*, is *explained by*, or is *dependent* on some other variable.\n:::\n\n- A bivariate regression refers to a regression including two variables or more variables?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nTwo variables. Bi -- two; variate -- variables\n:::\n\n- What is a confounding variable?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nA variable that *effects* both the dependent and independent variable. It is not a variable that is effected by either of the two.\n:::\n\n- What plot is appropriate for describing the bivariate relationship between a categorical variable and a continuous variable?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\nA two-way boxplot! The categorical variable goes on the x-axis and the continuous variable would be on the y-axis. Make sure to know which plots are most appropriate for different types of data!\n:::\n\n- How would I interpret @tbl-bivariate-regression from a bivariate regression model?\n\n\n::: {#tbl-bivariate-regression .cell tbl-cap='The effect of family income on feelings toward Hillary Clinton'}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 43.643*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (1.218) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> faminc </td>\n   <td style=\"text-align:center;\"> −0.032 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.035) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 1178 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Adj. </td>\n   <td style=\"text-align:center;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 11822.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 11837.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Log.Lik. </td>\n   <td style=\"text-align:center;\"> −5908.086 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 36.47 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Data source: Waffles dataset (McElreath 2020).</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Credit: damoncroberts.com</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Coefficient estimates from OLS.</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors in parentheses</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nFor every unit increase in family income, I would expect a ``-0.032`` decrease in favorable attitudes directed toward Hillary Clinton. The probability that the effect of family income on feelings toward Hillary Clinton would be this large or larger if the true effect were actually 0 is ``37.336``. It seems relatively plausible that the effect of income on feelings toward Hillary Clinton is actually zero.\n:::\n\n- For @tbl-bivariate-regression, what does the constant represent?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nIt reflects the variation in Feelings toward Hillary Clinton (the dependent variable) that is not explained by the independent and control variables I include in my model. It reflects the baseline feeling toward Hillary Clinton for people that have 0 family income. It is the y-intercept.\n:::\n\n- What does the p-value of a model represent and what does it tell me about statistical significance?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nThe p-value states the probability that I'd observe an effect (my $\\beta$ coefficient) that large or larger if the actual effect is zero.\n\nSmaller values means it is more implausible that I would have come up with a $\\beta$ coefficient if the effect of the independent variable on the dependent variable were actually zero.\n\nThis means that the smaller the p-value, the better for statistical significance! Usually the standard is: if your p-value is less than 0.05, then you have a statistically significant result on your hands.\n:::\n\n- What is a residual?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nIt is the difference between the *observed value* (what I have in my data) and the *predicted value* I get from my regression model (or line of best fit if I plot it). It reflects how well my particular regression fits to my data. The larger the residuals, the worse my model is doing in predicting my observed values.\n:::\n\n- Knowing this about a residual, what does my standard error tell me?\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nThe standard error is an estimate of how uncertain we are about our model. It tells us that, when I am wrong (when my residual is not equal to zero), just how \"off\" am I? When I am wrong, is my residual huge or small? The smaller the standard error, the better. It would mean that, if I am off, my residuals aren't all that large on average.\n:::\n\n- Say I give you @tbl-interaction-regression to interpret, how would you go about doing that?\n\n\n::: {#tbl-interaction-regression .cell tbl-cap='The effect of family income on feelings toward Hillary Clinton, conditional on gender.'}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 40.746*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (1.749) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> faminc </td>\n   <td style=\"text-align:center;\"> −0.069 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.053) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> genderFemale </td>\n   <td style=\"text-align:center;\"> 5.702* </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (2.429) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> faminc × genderFemale </td>\n   <td style=\"text-align:center;\"> 0.063 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.071) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 1178 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.010 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Adj. </td>\n   <td style=\"text-align:center;\"> 0.007 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 11815.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 11840.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Log.Lik. </td>\n   <td style=\"text-align:center;\"> −5902.616 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 36.30 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Data source: Waffles dataset (McElreath 2020).</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Credit: damoncroberts.com</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Coefficient estimates from OLS.</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors in parentheses</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\nWhen I am looking at male respondents (when family income equals zero), for every unit increase in family income, there is a ``-0.069`` unit decrease in feelings toward Hillary Clinton. This effect does not appear statistically significant. When Looking at Female individuals with zero income, they tend to report ``5.702`` points higher on their feelings toward Hillary Clinton relative to Males with zero income. This does not appear to be statistically significant. We see that for every unit increase in family income, Women tend to report ``0.063`` points higher on their feelings toward Hillary Clinton relative to males. This effect also does not appear to be statistically significant. \n:::\n\n- If instead of reporting standard errors and the p-values, how would I interpret @tbl-confidence-intervals that reports confidence intervals instead?\n\n\n::: {#tbl-confidence-intervals .cell tbl-cap='The effect of family income on feelings toward Hillary Clinton'}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 40.179 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> [36.983, 43.375] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> faminc </td>\n   <td style=\"text-align:center;\"> −0.034 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> [−0.103, 0.035] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> genderFemale </td>\n   <td style=\"text-align:center;\"> 6.759 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> [2.599, 10.920] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 1178 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.009 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Adj. </td>\n   <td style=\"text-align:center;\"> 0.008 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 11814.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 11834.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Log.Lik. </td>\n   <td style=\"text-align:center;\"> −5903.015 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 36.31 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Data source: Waffles dataset (McElreath 2020).</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Credit: damoncroberts.com</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Coefficient estimates from OLS.</td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors in parentheses</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n:::{.callout-note collapse=\"true\"}\n\n## Answer\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}