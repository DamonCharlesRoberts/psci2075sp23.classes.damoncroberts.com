# Areas for improvement

I wanted to quickly point out some areas that people seem hung up on in the assignments and on the midterm. Hopefully this will be a nice set of reminders! ðŸ˜Š

## When asked to report regression results, put it in a table

I have seen more and more folks lately either not reporting the results of a regression at all or just using the `summary()` function and pasting the output into the documents.

Both of these provide incomplete information that will make it harder for you to interpret the results of your regression and it will also give me (the reader) insufficient amount of information to see the results of your analyses.

So, be sure that you use either the `stargazer()` function from the `stargazer` package [@stargazer] or the `modelsummary()` function from the `modelsummary` package. These are relatively easy to use. Here is an example below.

```{.r}

# Run my regression
regression <- lm( # store the result in an object called regression
    formula = Y ~ X + Z # Fit this regression where Y is the dependent variable and X and Z are the independent variables
    , data = MYDATASET # These variables can be found in this dataset called MYDATASET
)

# Put the regression results in a table
    #* With the stargazer package
stargazer( # make a table of regression outputs
    regression # here is the stored result from my regression above
    , type = "text" # make it a table that I can copy and paste into a word document
)
    #* With the modelsummary package
modelsummary( # make a table of regression outputs
    regression # here is the stored result from my regression above
    , stars = TRUE # include stars based on p-values
    , output = "myRegressionTable.docx" # store the table in a word document called myRegressionTable
)
```

## Difference of means test (t-test)

To perform a difference of means test, also called a t-test, in R is quite straight forward. You can just use the `t.test()` function to do this. Then you'd want to interpret the t-value calculated by it, which is just the difference in the means between the two variables and then the p-value to determine whether that difference in the means is statistically significant or not.

```{.r}
t.test(MYDATASET$Y ~ MYDATASET$X)
```

## Be careful about how to interpret your regression results!

Folks often make the mistake of either only interpreting the $\beta$ coefficient or, more commonly, only interpreting the statistical significance of the effect. Remember that we need to discuss both! The $\beta$ coefficient tells us the size of the relationship between the two variables and the p-value tells us whether or not we believe that it is likely this relationship exists outside of our sample -- for our population.

Another problem that I see happens here is that people will only interpret the results for *some* of the variables in the regression. You should make sure that you interpret *all* of the variables in your regression model.

### General template for interpreting regression results

>For every one unit increase in [my independent variable], I'd expect a [$\beta$] unit [increase/decrease] in my [dependent variable] when I hold my other independent variables constant. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\beta$ coefficient this large or larger if the true relationship between these two variables was zero.

### Template for interpreting regression results for a dichotomous independent variable

>The difference between [the baseline category/what it means when the variable is 0] and [the category when the variable is 1] is [$\beta$] units [greater/smaller] when I hold my other independent variables constant. This difference [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\beta$ coefficient this large or larger if the true relationship between these two variables was zero.

### Template for interpreting regression results with an interaction term

For the continuous independent variable:

>When [the other independent variable] equals 0, a one unit increase in [my continuous independent variable], I'd expect a [$\beta$] unit [increase/decrease] in my [dependent variable]. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\beta$ coefficient this large or larger if the true relationship between these two variables was zero. 

For the dichotomous independent variable:

>When [the other independent variable] equals 0, a one unit increase in [my continuous independent variable], I'd expect a [$\beta$] unit [increase/decrease] in my [dependent variable]. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\beta$ coefficient this large or larger if the true relationship between these two variables was zero. 

For the interaction term:

>When [one of your continuous independent variables] increase by one unit, the difference between [the baseline category for your dichotmous independent variable/what it means when the dichotomous variable is zero] [increases/decreases]. This effect [is/is not] statistically significant. This means that it is relatively [plausible/implausible] that I'd have a $\beta$ coefficient this large or larger if the true relationship was zero.

You can also interpret these results with a plot with the `visreg` package as well instead of a table. This can sometimes be easier for newer folks. You will still want to interpret the same components as you do above with a table, but you can do it with a table. You can use this code to make that plot with `visreg`.

```{.r}
# Run my regression
regression <- lm( # store the result in an object called regression
    formula = Y ~ Continuous_Variable + Dichotomous_Variable + Continuous_Variable:Dichotomous_Variable
    , data = MYDATASET # These variables can be found in this dataset called MYDATASET
)

visreg( # make a plot to show the expected value with an interaction
    regression, # use the results from my regression model made above
    ,"Continous_Variable" 
    , by = "Dichotomous_Variable"
    , band=FALSE
    , overlay=TRUE
)
```

You have another option to make the same plot with the `modelsummary` package.

```{.r}
# Run my regression
regression <- lm( # store the result in an object called regression
    formula = Y ~ Continuous_Variable + Dichotomous_Variable + Continuous_Variable:Dichotomous_Variable
    , data = MYDATASET # These variables can be found in this dataset called MYDATASET
)

plot_predictions( # plot predicted values from this
    regression, # plot the interaction model
    condition = c("Continuous_Variable", "Dichotomous_Variable")
) +
theme_minimal() +
labs(
    y = "Y",
    x = "Continuous_Variable",
    caption = "Data source: MYDATASET.\n Effect of Continous_Variable on Y, conditional on Dichotomous_Variable."
)
### Interpreting the regression with confidence intervals

If you are asked to interpret the statistical significance of a regression model by its confidence intervals rather than the p-value, you can often use what is called a coefficient plot to do so!

These coefficient plots are relatively easy to create. One option would be to do this with the `modelsummary` package:

```{.r}

# Run my regression
regression <- lm( # store the result in an object called regression
    formula = Y ~ X + Z # Fit this regression where Y is the dependent variable and X and Z are the independent variables
    , data = MYDATASET # These variables can be found in this dataset called MYDATASET
)

modelplot( # make a plot with the CI's
    regression # with the bivariate regression
    ,coef_omit="Intercept" # do not include the intercept term
) +
geom_vline(
    aes(xintercept = 0),
    linetype = 2
)
```

OR with the `texreg` package:

```{.r}
# Run my regression
regression <- lm( # store the result in an object called regression
    formula = Y ~ X + Z # Fit this regression where Y is the dependent variable and X and Z are the independent variables
    , data = MYDATASET # These variables can be found in this dataset called MYDATASET
)

plotreg( # make a plot with the CI's
    bivariate # with the bivariate regression
    ,omit.coef = "(Intercept)" # do not include the intercept term
)
```